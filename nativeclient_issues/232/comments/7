<ns0:entry xmlns:ns0="http://www.w3.org/2005/Atom" xmlns:ns1="http://schemas.google.com/g/2005" xmlns:ns2="http://schemas.google.com/projecthosting/issues/2009" ns1:etag="W/&quot;A0YCQ347eCl7ImA9WxBUEEk.&quot;">
		<ns0:id>http://code.google.com/feeds/issues/p/nativeclient/issues/232/comments/full/7</ns0:id><ns0:author>
			<ns0:name>dt...@codeaurora.org</ns0:name><ns0:uri>/u/102710273696022658094/</ns0:uri></ns0:author><ns0:content type="html">Sorry for the confusion, let me try again. 

My reference to elf-header should have read elf+program headers and I am referring to 
the headers of the sel_ldr executable image (trusted). Also, I have attached a 
capture of the page mapping from /proc for the sel_ldr stopped at main entry and 
again stopped just before entering a Nacl-App (hello_world).

In order to reserve (allocate but not load, hence pages are not consumed) the 
trampoline+sandbox+guard-buffer we introduced a new section in the trusted linker 
script. This section starts at 10000x (we did keep the entry point for sel_ldr above 
0x40000000+ mark). As a consequence, the linker moved the headers (elf + program) for 
the sel_ldr image to just before this new section. Initially we did not realize the 
impact to the header placement. After experimenting with dynamic linking of the 
sel_ldr (currently it is statically linked)  we realized where the headers were being 
placed (we traced through what the kernel's loader was doing and noticed the accesses 
to the elf-header). 

Worried about security, we attempted to move these headers back into trusted space 
but were not successful (problems occurred with the kernel's loader). Our final 
solution was to introduce an additional small dummy section (before the sandbox 
section) to force placement of the headers starting at 8000x. This allowed remapping 
the page with the headers just before the sel_ldr loads the Nacl-app. Unfortunately, 
the kernel's loader wants to access the elf header during sel_ldr process exit so we 
remap and move the headers back into place on exit of the Nacl-app. 

NOTE: We did not change the original mmap call being made for the sandbox.

This removed the need for the call to mallopt described in an earlier comment. We 
have not attempted testing with multiple/concurrent NaCl modules (i.e. multiple 
sel_ldr processes). Also, we no longer need to run with the overcommit policy 
adjustment (e.g. cat /proc/sys/vm/overcommit_memory = 0). We are testing on armv7 
hardware w/ kernel split at 2G/2G.</ns0:content><ns0:updated>2010-02-24T22:06:02.000Z</ns0:updated><ns0:published>2010-02-24T22:06:02.000Z</ns0:published><ns2:updates /><ns0:title>Comment 7 by dt...@codeaurora.org</ns0:title><ns0:link href="http://code.google.com/p/nativeclient/issues/detail?id=232#c7" rel="alternate" type="text/html" /><ns0:link href="https://code.google.com/feeds/issues/p/nativeclient/issues/232/comments/full/7" rel="self" type="application/atom+xml" /></ns0:entry>